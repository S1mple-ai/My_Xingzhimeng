#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ•°æ®åº“ç´¢å¼•ã€ç¼“å­˜å’ŒæŸ¥è¯¢ä¼˜åŒ–æ•ˆæœ
"""

import time
import logging
from database import DatabaseManager
import streamlit as st

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PerformanceTester:
    def __init__(self):
        self.db = DatabaseManager()
        # åˆå§‹åŒ–session_stateæ¨¡æ‹Ÿ
        if not hasattr(st, 'session_state'):
            st.session_state = {}
    
    def test_database_queries(self):
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        logger.info("ğŸ” å¼€å§‹æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•...")
        
        tests = [
            ("è·å–å®¢æˆ·åˆ—è¡¨", lambda: self.db.get_customers()),
            ("è·å–é¢æ–™åˆ—è¡¨", lambda: self.db.get_fabrics()),
            ("è·å–åº“å­˜åˆ—è¡¨", lambda: self.db.get_inventory_items()),
            ("åˆ†é¡µæŸ¥è¯¢è®¢å•", lambda: self.db.get_orders_paginated(page=1, page_size=10)),
            ("æœç´¢è®¢å•", lambda: self.db.get_orders_paginated(page=1, page_size=10, search_term="æµ‹è¯•")),
            ("çŠ¶æ€ç­›é€‰è®¢å•", lambda: self.db.get_orders_paginated(page=1, page_size=10, status_filter="pending")),
        ]
        
        results = []
        for test_name, test_func in tests:
            # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆæ— ç¼“å­˜ï¼‰
            start_time = time.time()
            result1 = test_func()
            first_time = time.time() - start_time
            
            # ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰
            start_time = time.time()
            result2 = test_func()
            second_time = time.time() - start_time
            
            # è®¡ç®—ç¼“å­˜æ•ˆæœ
            cache_improvement = ((first_time - second_time) / first_time * 100) if first_time > 0 else 0
            
            results.append({
                'test': test_name,
                'first_time': first_time,
                'second_time': second_time,
                'improvement': cache_improvement
            })
            
            status = "ğŸŸ¢" if first_time < 0.1 else "ğŸŸ¡" if first_time < 0.5 else "ğŸ”´"
            cache_status = "ğŸš€" if cache_improvement > 50 else "âš¡" if cache_improvement > 10 else "â¡ï¸"
            
            logger.info(f"{status} {test_name}: {first_time:.3f}s â†’ {second_time:.3f}s {cache_status} ç¼“å­˜æå‡: {cache_improvement:.1f}%")
        
        return results
    
    def test_cache_effectiveness(self):
        """æµ‹è¯•ç¼“å­˜æœ‰æ•ˆæ€§"""
        logger.info("ğŸ’¾ å¼€å§‹ç¼“å­˜æœ‰æ•ˆæ€§æµ‹è¯•...")
        
        # æ¸…ç†æ‰€æœ‰ç¼“å­˜
        self.db.clear_cache()
        
        # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
        cache_tests = [
            ("å®¢æˆ·æ•°æ®ç¼“å­˜", self.db.get_customers),
            ("é¢æ–™æ•°æ®ç¼“å­˜", self.db.get_fabrics),
            ("åº“å­˜æ•°æ®ç¼“å­˜", self.db.get_inventory_items),
        ]
        
        for test_name, test_func in cache_tests:
            # å¤šæ¬¡è°ƒç”¨æµ‹è¯•ç¼“å­˜
            times = []
            for i in range(5):
                start_time = time.time()
                result = test_func()
                execution_time = time.time() - start_time
                times.append(execution_time)
            
            avg_time = sum(times) / len(times)
            first_time = times[0]
            cached_avg = sum(times[1:]) / len(times[1:]) if len(times) > 1 else 0
            
            improvement = ((first_time - cached_avg) / first_time * 100) if first_time > 0 and cached_avg > 0 else 0
            
            logger.info(f"ğŸ“Š {test_name}: é¦–æ¬¡ {first_time:.3f}s, ç¼“å­˜å¹³å‡ {cached_avg:.3f}s, æå‡ {improvement:.1f}%")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        logger.info("ğŸ§  å¼€å§‹å†…å­˜ä½¿ç”¨æµ‹è¯•...")
        
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        
        # è·å–åˆå§‹å†…å­˜
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œä¸€ç³»åˆ—æ“ä½œ
        for i in range(10):
            self.db.get_customers()
            self.db.get_fabrics()
            self.db.get_inventory_items()
            self.db.get_orders_paginated(page=i+1, page_size=10)
        
        # è·å–æœ€ç»ˆå†…å­˜
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        logger.info(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {initial_memory:.1f}MB â†’ {final_memory:.1f}MB (å¢åŠ  {memory_increase:.1f}MB)")
        
        # æ¸…ç†ç¼“å­˜åçš„å†…å­˜
        self.db.clear_cache()
        after_clear_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_freed = final_memory - after_clear_memory
        
        logger.info(f"ğŸ§¹ æ¸…ç†ç¼“å­˜å: {after_clear_memory:.1f}MB (é‡Šæ”¾ {memory_freed:.1f}MB)")
    
    def test_concurrent_access(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®æ€§èƒ½"""
        logger.info("ğŸ”„ å¼€å§‹å¹¶å‘è®¿é—®æµ‹è¯•...")
        
        import threading
        import queue
        
        results_queue = queue.Queue()
        
        def worker():
            start_time = time.time()
            try:
                # æ¨¡æ‹Ÿå¹¶å‘æŸ¥è¯¢
                customers = self.db.get_customers()
                fabrics = self.db.get_fabrics()
                inventory = self.db.get_inventory_items()
                orders = self.db.get_orders_paginated()
                
                execution_time = time.time() - start_time
                results_queue.put(('success', execution_time))
            except Exception as e:
                results_queue.put(('error', str(e)))
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹
        threads = []
        thread_count = 5
        
        start_time = time.time()
        for i in range(thread_count):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        
        # æ”¶é›†ç»“æœ
        success_count = 0
        error_count = 0
        execution_times = []
        
        while not results_queue.empty():
            status, result = results_queue.get()
            if status == 'success':
                success_count += 1
                execution_times.append(result)
            else:
                error_count += 1
                logger.error(f"å¹¶å‘æµ‹è¯•é”™è¯¯: {result}")
        
        avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        logger.info(f"ğŸ”„ å¹¶å‘æµ‹è¯•ç»“æœ: {success_count}/{thread_count} æˆåŠŸ")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.3f}s, å¹³å‡å•çº¿ç¨‹: {avg_time:.3f}s")
    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š...")
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'database_stats': {},
            'performance_results': {},
            'optimization_summary': {}
        }
        
        # æ•°æ®åº“ç»Ÿè®¡
        try:
            import sqlite3
            conn = sqlite3.connect(self.db.db_path)
            cursor = conn.cursor()
            
            # è·å–è¡¨å¤§å°
            tables = ['customers', 'orders', 'order_items', 'inventory', 'fabrics']
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                report['database_stats'][table] = count
            
            # è·å–ç´¢å¼•æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
            index_count = cursor.fetchone()[0]
            report['database_stats']['indexes'] = index_count
            
            conn.close()
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")
        
        # æ€§èƒ½æµ‹è¯•ç»“æœ
        query_results = self.test_database_queries()
        report['performance_results']['query_tests'] = query_results
        
        # ç¼“å­˜æµ‹è¯•
        self.test_cache_effectiveness()
        
        # å†…å­˜æµ‹è¯•
        try:
            self.test_memory_usage()
        except ImportError:
            logger.warning("psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        
        # å¹¶å‘æµ‹è¯•
        self.test_concurrent_access()
        
        # ä¼˜åŒ–æ€»ç»“
        total_queries = len(query_results)
        fast_queries = len([r for r in query_results if r['first_time'] < 0.1])
        cached_improvements = [r for r in query_results if r['improvement'] > 10]
        
        report['optimization_summary'] = {
            'total_queries_tested': total_queries,
            'fast_queries_count': fast_queries,
            'fast_queries_percentage': (fast_queries / total_queries * 100) if total_queries > 0 else 0,
            'cache_improvements_count': len(cached_improvements),
            'avg_cache_improvement': sum(r['improvement'] for r in cached_improvements) / len(cached_improvements) if cached_improvements else 0
        }
        
        # è¾“å‡ºæŠ¥å‘Šæ‘˜è¦
        logger.info("ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Šæ‘˜è¦:")
        logger.info(f"   ğŸš€ å¿«é€ŸæŸ¥è¯¢: {fast_queries}/{total_queries} ({report['optimization_summary']['fast_queries_percentage']:.1f}%)")
        logger.info(f"   ğŸ’¾ ç¼“å­˜ä¼˜åŒ–: {len(cached_improvements)} é¡¹æŸ¥è¯¢è·å¾—æ˜¾è‘—æå‡")
        logger.info(f"   âš¡ å¹³å‡ç¼“å­˜æå‡: {report['optimization_summary']['avg_cache_improvement']:.1f}%")
        logger.info(f"   ğŸ” æ•°æ®åº“ç´¢å¼•: {report['database_stats'].get('indexes', 0)} ä¸ª")
        
        return report
    
    def run_full_test(self):
        """è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´æ€§èƒ½æµ‹è¯•...")
        
        start_time = time.time()
        report = self.generate_performance_report()
        total_time = time.time() - start_time
        
        logger.info(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f}s")
        logger.info("ğŸ‰ æ€§èƒ½ä¼˜åŒ–éªŒè¯æˆåŠŸï¼")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    try:
        tester = PerformanceTester()
        tester.run_full_test()
    except Exception as e:
        logger.error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()